# RFC 2 — Semantic Search & RAG Microservice

## Overview
Develop a **semantic search API** that supports retrieval-augmented generation (RAG). It will embed documents, index them in a vector store, and expose a Spring Boot API for semantic queries with responses generated by a transformer-based model.

## Problem Statement
Keyword search (e.g., SQL/Elasticsearch) is insufficient for semantic matching. Goal: provide low-latency semantic search (sub-500 ms for 100k documents) with RAG responses.

## Architecture
- **Document Store:** MySQL/ElasticSearch for metadata + Faiss/Elastic vector DB for embeddings  
- **Embedder Service:** Python service (Hugging Face model) to embed documents + queries  
- **Index Updater:** Kafka pipeline for new/updated docs → re-embedding + index update  
- **Query Service:** Java Spring Boot API → retrieves top-k vectors from vector DB → calls LLM/RAG model for answer  
- **Monitoring:** Prometheus metrics for query latency, hit rates  

## Milestones
1. Week 1–2: Setup DB + vector store (Faiss/Elastic)  
2. Week 3–4: Implement embedding service + batch ingest pipeline  
3. Week 5: Build Spring Boot query service + REST APIs  
4. Week 6: Integrate RAG model for natural language responses  
5. Week 7: Optimize query latency (<500ms), scale to 100k+ docs  
6. Week 8: Deploy to Kubernetes, expose public demo  

## Test Plan
- **Unit tests:** embedding correctness, API endpoints, indexing pipeline  
- **Integration tests:** API → vector DB → RAG model  
- **Load tests:** Query latency at scale (concurrent 100 QPS)  
- **Accuracy tests:** Evaluate search precision/recall on sample queries  
- **Acceptance criteria:** P95 query latency < 500 ms, >80% semantic match accuracy  
